"""
Pattern Composition Engine

This module provides a mechanism to detect composite patterns from atomic patterns
generated by individual evaluators. It allows for detecting complex behavioral patterns
that require multiple evidence points or specific temporal sequences.
"""
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set, Any
from enum import Enum
from src.models.risk_models import Pattern, RiskCategory
from src.utils.log_util import get_logger

logger = get_logger()


class CompositePatternRule:
    """
    Rule definition for detecting a composite pattern from atomic patterns.
    
    Attributes:
        rule_id (str): Unique identifier for the rule
        pattern_ids (List[str]): List of atomic pattern IDs this rule looks for
        sequence_matters (bool): Whether the patterns must appear in a specific sequence
        min_patterns_required (int): Minimum number of patterns required to match
        require_all_patterns (bool): If True, ALL patterns in pattern_ids must be present
        time_window_minutes (int): Time window in which patterns must occur
        category (RiskCategory): Primary risk category for this pattern
        confidence_boost (float): Boost applied to confidence if rule matches
        message (str): Message template for the resulting composite pattern
    """

    def __init__(
            self,
            rule_id: str,
            pattern_ids: List[str],
            category: RiskCategory,
            time_window_minutes: int = 1440,  # 24 hours default
            sequence_matters: bool = False,  # if order matters
            min_patterns_required: Optional[int] = None,
            require_all_patterns: bool = False,  # if ALL pattern types are required
            confidence_boost: float = 0.1,
            message: str = "Composite pattern detected"
    ):
        self.rule_id = rule_id
        self.pattern_ids = pattern_ids
        self.sequence_matters = sequence_matters
        self.min_patterns_required = min_patterns_required or len(pattern_ids)
        self.require_all_patterns = require_all_patterns
        self.time_window_minutes = time_window_minutes
        self.category = category
        self.confidence_boost = confidence_boost
        self.message = message


class PatternCompositionEngine:
    """
    Engine for detecting composite patterns from atomic patterns based on rules.
    
    This engine processes atomic patterns and applies composition rules to detect
    higher-level behavioral patterns that may indicate cognitive biases.
    """

    def __init__(self):
        """Initialize the pattern composition engine with default rules."""
        self.rules: List[CompositePatternRule] = []
        self._initialize_default_rules()

    def _initialize_default_rules(self):
        """Initialize default composition rules for common biases."""

        self.rules.append(CompositePatternRule(
            rule_id="rapid_overtrading",
            pattern_ids=["daily_trade_limit", "cooldown_limit"],
            category=RiskCategory.OVERTRADING,
            time_window_minutes=720,  # 12 hours
            sequence_matters=False,
            min_patterns_required=2,
            confidence_boost=0.15,
            message="Multiple overtrading indicators detected"
        ))

        self.rules.append(CompositePatternRule(
            rule_id="volume_burst",
            pattern_ids=["daily_volume_exceeded", "single_job_amount_limit"],
            category=RiskCategory.OVERTRADING,
            time_window_minutes=360,
            sequence_matters=False,
            min_patterns_required=2,
            confidence_boost=0.2,
            message="Trading volume burst detected"
        ))

        self.rules.append(CompositePatternRule(
            rule_id="loss_escalation",
            pattern_ids=["consecutive_loss", "position_size_increase"],
            category=RiskCategory.SUNK_COST,
            time_window_minutes=1440,  # 24h
            sequence_matters=True,
            require_all_patterns=True,  # REQUIRE both patterns to be present
            confidence_boost=0.25,
            message="Loss followed by increasing position size"
        ))

        self.rules.append(CompositePatternRule(
            rule_id="repeated_loss_chasing",
            pattern_ids=["daily_loss_limit", "trade_frequency_increase", "increased_risk_taking"],
            category=RiskCategory.SUNK_COST,
            time_window_minutes=1440,
            sequence_matters=True,
            min_patterns_required=2,  # Only need 2 out of 3 patterns
            require_all_patterns=False,
            confidence_boost=0.2,
            message="Daily loss followed by increased trading behavior"
        ))

    def add_rule(self, rule: CompositePatternRule):
        """Add a new composition rule to the engine."""
        self.rules.append(rule)
        logger.info(f"Added composite pattern rule: {rule.rule_id}")

    def process_patterns(self, patterns: List[Pattern], current_time: Optional[datetime] = None) -> List[Pattern]:
        """
        Process a list of atomic patterns and detect composite patterns.
        
        Args:
            patterns: List of atomic patterns from evaluators
            current_time: Current time (defaults to now)
            
        Returns:
            List of composite patterns detected (using the same Pattern model)
        """
        if not patterns:
            return []

        if current_time is None:
            current_time = datetime.now()

        composite_patterns = []

        # Index patterns by ID for efficient lookup
        patterns_by_id: Dict[str, List[Pattern]] = {}
        for pattern in patterns:
            if pattern.pattern_id not in patterns_by_id:
                patterns_by_id[pattern.pattern_id] = []
            patterns_by_id[pattern.pattern_id].append(pattern)

        # Apply each rule
        for rule in self.rules:
            matching_patterns = self._match_rule(rule, patterns_by_id, current_time)
            if matching_patterns:
                composite_pattern = self._create_composite_pattern(rule, matching_patterns)
                composite_patterns.append(composite_pattern)
                logger.info(
                    f"Detected composite pattern: {rule.rule_id} with confidence {composite_pattern.confidence:.2f}")

        return composite_patterns

    def _match_rule(
            self,
            rule: CompositePatternRule,
            patterns_by_id: Dict[str, List[Pattern]],
            current_time: datetime
    ) -> List[Pattern]:
        """
        Check if a rule matches the available patterns based on their temporal relationships.
        
        Args:
            rule: The rule to check
            patterns_by_id: Dictionary of patterns indexed by pattern_id
            current_time: Current time for time window checks
            
        Returns:
            List of matching patterns if rule conditions are met, empty list otherwise
        """
        # Check if we have enough of the required pattern types
        pattern_ids_found = set(patterns_by_id.keys()).intersection(set(rule.pattern_ids))
        
        # If rule requires ALL pattern types, check that all are present
        if rule.require_all_patterns and len(pattern_ids_found) != len(rule.pattern_ids):
            return []
        
        # Otherwise, check if minimum number of pattern types are present
        elif len(pattern_ids_found) < rule.min_patterns_required:
            return []
        
        # Collect all candidate patterns
        candidate_patterns = []
        for pattern_id in rule.pattern_ids:
            if pattern_id in patterns_by_id:
                candidate_patterns.extend(patterns_by_id[pattern_id])
        
        # First apply recency filter - only consider patterns from recent enough history
        # This keeps processing manageable by filtering very old patterns
        max_history_window = timedelta(minutes=rule.time_window_minutes * 4)  # 4x for flexibility
        earliest_history_cutoff = current_time - max_history_window
        
        recent_patterns = []
        for pattern in candidate_patterns:
            # Get pattern time boundaries
            p_start = pattern.start_time
            p_end = pattern.end_time or pattern.start_time
            
            # A pattern is "recent enough" if any part of it occurs after the cutoff:
            # 1. Pattern ends after cutoff, OR
            # 2. Pattern has duration and starts before cutoff but ends after cutoff
            if (p_end is not None and p_end >= earliest_history_cutoff) or \
               (pattern.end_time is not None and p_start < earliest_history_cutoff and p_end >= earliest_history_cutoff):
                recent_patterns.append(pattern)
        
        # Check if we still have the required pattern types after time filtering
        pattern_types_found = {p.pattern_id for p in recent_patterns}
        required_types = set(rule.pattern_ids)
        
        # If rule requires ALL pattern types, check that all are still present after time filtering
        if rule.require_all_patterns and not pattern_types_found.issuperset(required_types):
            return []
        # Otherwise, check if minimum number of pattern types are present after time filtering
        elif len(pattern_types_found.intersection(required_types)) < rule.min_patterns_required:
            return []
        
        # Now find valid combinations based on relative time differences
        valid_combinations = []
        
        # Sort patterns by start_time for processing
        sorted_patterns = sorted(recent_patterns, key=lambda p: p.start_time)
        
        # For rules with exactly 2 pattern types (most common case)
        if len(rule.pattern_ids) == 2 and len(pattern_ids_found) >= 2:
            pattern_id1, pattern_id2 = rule.pattern_ids[:2]
            
            # Group patterns by type
            patterns_of_type1 = [p for p in sorted_patterns if p.pattern_id == pattern_id1]
            patterns_of_type2 = [p for p in sorted_patterns if p.pattern_id == pattern_id2]
            
            # Check each possible pair
            for p1 in patterns_of_type1:
                for p2 in patterns_of_type2:
                    # Skip if timestamps not available
                    if p1.start_time is None or p2.start_time is None:
                        continue
                    
                    # Determine time relationship
                    p1_start = p1.start_time
                    p1_end = p1.end_time or p1.start_time
                    p2_start = p2.start_time
                    p2_end = p2.end_time or p2.start_time
                    
                    # Check sequence if required
                    if rule.sequence_matters:
                        # For sequence, pattern1 should end before pattern2 starts (or at the same time)
                        if p1_end > p2_start:
                            continue  # Wrong sequence - p1 ends after p2 starts
                    
                    # Calculate temporal distance between patterns
                    # If patterns overlap or one contains the other, distance is 0
                    # Otherwise, it's the gap between the end of one and start of the other
                    if max(p1_start, p2_start) <= min(p1_end, p2_end):
                        # Patterns overlap or one contains the other
                        time_diff_minutes = 0
                    else:
                        # Calculate gap between patterns
                        if p1_end < p2_start:
                            # p1 is before p2
                            time_diff_minutes = (p2_start - p1_end).total_seconds() / 60
                        else:
                            # p2 is before p1
                            time_diff_minutes = (p1_start - p2_end).total_seconds() / 60
                    
                    # Check if within time window
                    if time_diff_minutes <= rule.time_window_minutes:
                        valid_combinations.append([p1, p2])
        
        # For more complex rules with 3+ pattern types
        elif len(pattern_ids_found) >= rule.min_patterns_required:
            # Group patterns by type for faster access
            patterns_by_type = {pid: [] for pid in pattern_ids_found}
            for p in sorted_patterns:
                if p.pattern_id in patterns_by_type:
                    patterns_by_type[p.pattern_id].append(p)
            
            # For sequence-dependent rules, use sliding window approach
            if rule.sequence_matters:
                # Consider all valid starting points in the sequence
                valid_starts = []
                for start_idx in range(len(rule.pattern_ids) - rule.min_patterns_required + 1):
                    valid_starts.append(start_idx)
                
                # Try each valid starting point
                for start_idx in valid_starts:
                    start_pattern_id = rule.pattern_ids[start_idx]
                    
                    if start_pattern_id not in patterns_by_type:
                        continue
                    
                    # Try each possible starting pattern of the required type
                    for start_pattern in patterns_by_type[start_pattern_id]:
                        # Track sequence construction
                        combination = [start_pattern]
                        current_end_time = start_pattern.end_time or start_pattern.start_time
                        
                        # Try to build the sequence from this starting point
                        sequence_valid = True
                        
                        # For each subsequent pattern type in the sequence
                        for next_idx in range(start_idx + 1, len(rule.pattern_ids)):
                            next_pattern_id = rule.pattern_ids[next_idx]
                            
                            if next_pattern_id not in patterns_by_type:
                                sequence_valid = False
                                break
                            
                            # Find all patterns of this type that could follow in sequence
                            # (they must start after the previous pattern ends)
                            valid_next_patterns = [
                                p for p in patterns_by_type[next_pattern_id]
                                if p.start_time >= current_end_time
                            ]
                            
                            # If no valid next patterns, sequence can't be completed
                            if not valid_next_patterns:
                                sequence_valid = False
                                break
                            
                            # Choose the best next pattern (closest in time to minimize gaps)
                            best_next = min(
                                valid_next_patterns,
                                key=lambda p: (p.start_time - current_end_time).total_seconds()
                            )
                            
                            # Ensure the time gap isn't too large
                            time_gap = (best_next.start_time - current_end_time).total_seconds() / 60
                            if time_gap > rule.time_window_minutes:
                                sequence_valid = False
                                break
                            
                            # Add this pattern to our sequence
                            combination.append(best_next)
                            current_end_time = best_next.end_time or best_next.start_time
                            
                            # If we've found enough patterns to satisfy min_required, we can stop
                            # (but only if we've covered all required pattern types)
                            if len(combination) >= rule.min_patterns_required:
                                # Check if we have all required pattern types
                                found_types = {p.pattern_id for p in combination}
                                required_types = set(rule.pattern_ids[start_idx:next_idx+1])
                                
                                # If requiring all patterns, we need to have all pattern types from the rule
                                if rule.require_all_patterns and not found_types.issuperset(required_types):
                                    continue
                                # Otherwise, we just need to have enough of the required types
                                elif found_types.issuperset(required_types):
                                    break
                        
                        # If sequence is valid and meets minimum requirements
                        if sequence_valid and len(combination) >= rule.min_patterns_required:
                            # Calculate total time span from start of first to end of last
                            first_start = combination[0].start_time
                            last_end = combination[-1].end_time or combination[-1].start_time
                            
                            # Calculate pure duration (excluding gaps)
                            pattern_durations = 0
                            for p in combination:
                                p_duration = 0
                                if p.end_time:
                                    p_duration = (p.end_time - p.start_time).total_seconds() / 60
                                pattern_durations += p_duration
                            
                            # Calculate total time span including gaps
                            total_span_minutes = (last_end - first_start).total_seconds() / 60
                            
                            # Expand allowed window based on pattern durations
                            expanded_window = rule.time_window_minutes + pattern_durations
                            
                            # If sequence fits within expanded window, it's valid
                            if total_span_minutes <= expanded_window:
                                valid_combinations.append(combination)
            
            # For non-sequence rules, use temporal clustering approach
            else:
                # Sort all patterns by start time
                time_sorted_patterns = sorted(sorted_patterns, key=lambda p: p.start_time)
                
                # Try sliding window approach to find clusters
                for i, start_pattern in enumerate(time_sorted_patterns):
                    # Create a time window starting from this pattern
                    window_start_time = start_pattern.start_time
                    window_end_time = window_start_time + timedelta(minutes=rule.time_window_minutes)
                    
                    # Collect all patterns that overlap with the window in any way:
                    # 1. Pattern starts within window
                    # 2. Pattern ends within window
                    # 3. Pattern completely contains the window
                    # 4. Pattern is completely contained within the window
                    window_patterns = [start_pattern]
                    
                    for j in range(len(time_sorted_patterns)):
                        # Skip the starting pattern
                        if j == i:
                            continue
                            
                        next_pattern = time_sorted_patterns[j]
                        next_start = next_pattern.start_time
                        next_end = next_pattern.end_time or next_start
                        
                        # Check for any kind of overlap
                        # Two patterns overlap if start of one is before end of other, and vice versa
                        if (next_start <= window_end_time and next_end >= window_start_time):
                            window_patterns.append(next_pattern)
                    
                    # Check if window has enough unique pattern types from our rule
                    window_pattern_types = {p.pattern_id for p in window_patterns}
                    matching_types = window_pattern_types.intersection(rule.pattern_ids)
                    
                    # Check pattern requirements
                    # If rule requires ALL patterns, check that all are present
                    if rule.require_all_patterns and not window_pattern_types.issuperset(rule.pattern_ids):
                        continue
                    # Otherwise, check minimum required patterns
                    elif len(matching_types) < rule.min_patterns_required:
                        continue
                    
                    # Take one of each needed type that best fits the window
                    combination = []
                    for pid in rule.pattern_ids:
                        matches = [p for p in window_patterns if p.pattern_id == pid]
                        if matches:
                            # Choose the best match: 
                            # 1. Highest overlap with window
                            # 2. Highest confidence in case of tie
                            
                            def pattern_score(pattern):
                                p_start = pattern.start_time
                                p_end = pattern.end_time or p_start
                                
                                # Calculate overlap duration with window
                                overlap_start = max(p_start, window_start_time)
                                overlap_end = min(p_end, window_end_time)
                                
                                if overlap_end <= overlap_start:
                                    return 0  # No overlap
                                
                                overlap_duration = (overlap_end - overlap_start).total_seconds()
                                pattern_duration = (p_end - p_start).total_seconds()
                                
                                # Normalize by pattern duration and add confidence as tiebreaker
                                if pattern_duration > 0:
                                    return (overlap_duration / pattern_duration) + (pattern.confidence / 100)
                                else:
                                    return pattern.confidence
                            
                            best_match = max(matches, key=pattern_score)
                            combination.append(best_match)
                    
                    if len(combination) >= rule.min_patterns_required:
                        valid_combinations.append(combination)
        
        # If we found valid combinations, use the most recent/strongest one
        if valid_combinations:
            # For multiple valid combinations, prefer:
            # 1. More complete matches (more pattern types)
            # 2. More recent patterns (by end time of last pattern)
            # 3. Higher confidence patterns
            
            def score_combination(combo):
                unique_types = len(set(p.pattern_id for p in combo))
                recency = max(p.end_time or p.start_time for p in combo).timestamp()
                avg_confidence = sum(p.confidence for p in combo) / len(combo)
                return (unique_types, recency, avg_confidence)
            
            valid_combinations.sort(key=score_combination, reverse=True)
            
            # Return the best combination
            return valid_combinations[0]
        
        return []

    def _create_composite_pattern(self, rule: CompositePatternRule, matching_patterns: List[Pattern]) -> Pattern:
        """
        Create a composite pattern from matched atomic patterns.
        
        Args:
            rule: The rule that matched
            matching_patterns: The atomic patterns that matched the rule
            
        Returns:
            A new Pattern object representing the composite pattern
        """
        # Mark all component patterns as consumed
        for pattern in matching_patterns:
            pattern.consumed = True
            
        # Calculate the combined confidence
        base_confidence = sum(p.confidence for p in matching_patterns) / len(matching_patterns)
        boosted_confidence = min(1.0, base_confidence + rule.confidence_boost)

        # Collect all job IDs
        job_ids = set()
        for pattern in matching_patterns:
            if pattern.job_id:
                job_ids.update(pattern.job_id)

        # Determine time boundaries of the composite pattern
        start_times = [p.start_time for p in matching_patterns if p.start_time is not None]
        end_times = [p.end_time or p.start_time for p in matching_patterns if p.start_time is not None]
        
        composite_start_time = min(start_times) if start_times else None
        composite_end_time = max(end_times) if end_times else None

        # Create a cleaner, more user-friendly details structure
        details = {
            # Component reference section
            "components": [
                {
                    "id": p.internal_id,
                    "pattern_type": p.pattern_id,
                    "confidence": p.confidence
                } 
                for p in matching_patterns
            ],
            
            # Time information
            "time_span": {
                "duration_minutes": (composite_end_time - composite_start_time).total_seconds() / 60 
                if composite_start_time and composite_end_time else None
            }
        }
        
        # Add sequence information only if relevant
        if rule.sequence_matters:
            details["sequence_dependent"] = True
        
        # Define category weights with primary category having highest weight
        category_weights = {rule.category: 0.7}

        # Add secondary categories with lower weights
        secondary_categories = set()
        for pattern in matching_patterns:
            secondary_categories.update(pattern.category_weights.keys())

        # Remove the primary category to avoid duplication
        if rule.category in secondary_categories:
            secondary_categories.remove(rule.category)

        # Distribute remaining 0.3 weight among secondary categories
        if secondary_categories:
            secondary_weight = 0.3 / len(secondary_categories)
            for category in secondary_categories:
                category_weights[category] = secondary_weight

        # Create a descriptive message that explains what the composite represents
        message = rule.message
        
        # Add component count if we have multiple components
        if len(matching_patterns) > 1:
            message += f" ({len(matching_patterns)} related patterns)"

        # Create the composite pattern with time boundaries
        return Pattern(
            pattern_id=f"composite_{rule.rule_id}",
            job_id=list(job_ids) if job_ids else None,
            message=message,
            confidence=boosted_confidence,
            category_weights=category_weights,
            details=details,
            start_time=composite_start_time,
            end_time=composite_end_time,
            is_composite=True  # Mark as a composite pattern
        )
